---
title: "Confidence intervals for regression coefficients"
author: "Dr. D'Agostino McGowan"
output:
  xaringan::moon_reader:
    css: "slides.css"
    logo: img/icon.png
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r child = "setup.Rmd"}
```

layout: true

<div class="my-footer">
<span>
Dr. Lucy D'Agostino McGowan
</span>
</div> 

---

class: middle

# confidence intervals

If we use the same sampling method to select different samples and computed an interval estimate for each sample, we would expect the true population parameter ( $\beta_1$ ) to fall within the interval estimates 95% of the time.

---

## Confidence interval for $\hat\beta$

.center[
$\Huge \hat\beta_i \pm t^∗ \times SE_{\hat\beta_i}$
]

---


## Confidence interval for $\hat\beta$

.center[
$\Huge \hat\beta_i \pm t^∗ \times SE_{\hat\beta_i}$
]

* $t^*$ is the critical value for the $t_{n−p-1}$ density curve to obtain the desired confidence level
--

* Often we want a **95% confidence level**.  

---

## Let's do it in R

```{r}
X <- matrix(c(1, 1, 1, 1, 1,
              2, 3, 5, 1, 3), ncol = 2)
y <- c(1, 2, 5, 4, 2)
```

---

## Let's do it in R

```{r}
(beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y)
```

---

## Let's do it in R

```{r}
e <- y - X %*% beta_hat
var_e <- sum(e^2) / (5 - 2)
var_beta <-  var_e * solve(t(X) %*% X)
(se_beta <- sqrt(diag(var_beta)))
```

---

## Let's do it in R

.center[
$\Huge \hat\beta_i \pm t^∗ \times SE_{\hat\beta_i}$
]

```{r}
(t_star <- qt(0.975, 5 - 2))
```

--

.question[Why 0.975? I thought we want a 95% CI?]

--

* We want a 2-sided p-value!

---

## t-distribution

```{r, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(1)
library(tidyverse)
data.frame(t = rt(10000, df = 5-2)) %>%
  ggplot(aes(x = t)) +
  geom_histogram() +
  geom_vline(xintercept = c(2.35))
```

---

## t-distribution

```{r, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(1)
library(tidyverse)
data.frame(t = rt(10000, df = 5-2)) %>%
  ggplot(aes(x = t)) +
  geom_histogram() +
  geom_vline(xintercept = c(2.35, -2.35))
```

---

## t-distribution

```{r, echo = FALSE, message = FALSE, warning = FALSE}
data.frame(t = rt(10000, df = 5-2)) %>%
  ggplot(aes(x = t)) +
  geom_histogram() +
  geom_vline(xintercept = c(3.18, -3.18))
```

---

## Let's do it in R

.center[
$\Huge \hat\beta_i \pm t^∗ \times SE_{\hat\beta_i}$
]

.small[
```{r}
(t_star <- qt(0.975, 5 - 2))
(lb <- beta_hat - t_star * se_beta)
(ub <- beta_hat + t_star * se_beta)
```
]

--

* 95% CI $\hat\beta_0$: (-4.22, 7.40)
* 95% CI $\hat\beta_1$: (-1.44, 2.30)

---

## Let's do it in R

```{r}
lm_fit <- lm(y ~ X[,2])
confint(lm_fit)
```

---

## Confidence Regions

You can also calculate a _confidence region_ for more than one parameter.

$$(\hat\beta-\beta)^T\mathbf{X}^T\mathbf{X}(\hat\beta-\beta)\leq (p+1)\hat\sigma^2F^{\alpha}_{p+1, n-(p+1)}$$

--

* This will form an _ellipsoid_ region

---


## `r fa("laptop")` `Application Exercise`

y | x_1 | x_2
---|----|----
1 | 3 | 2
3 | 3 | 6
5 | 1 | 8
6 | 7 | 9
1 | 1 | 2

* Fit a model predicting `y` from `X`
* Calculate the confidence intervals "by hand"
* Check with the `confint` function
* Interpret these intervals
* Calculate the _joint_ confidence interval for $\beta_1$ and $\beta_2$




